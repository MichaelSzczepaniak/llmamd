{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef585d-dd55-4f86-8d56-687d4a11b3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1253221e-1757-4ce4-86f8-28b9f41e7be0",
   "metadata": {},
   "source": [
    "## Make a request to a ChatGPT model\n",
    "\n",
    "The following example is from:  https://platform.openai.com/docs/quickstart?context=python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfc7c8d-6685-4cf9-80fa-63b7ddd4c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "# \n",
    "# completion = client.chat.completions.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b818a22-bd21-47ce-8384-ad6241528cea",
   "metadata": {},
   "source": [
    "## Try generating related tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1e632f-3054-46ff-9799-ce793725cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of base data with spillovers fixed and duplicates removed: (7485, 5)\n",
      "shape of same base data with target == 0: (4297, 3)\n",
      "shape of same base data with target == 1: (3188, 3)\n",
      "\n",
      "index=0 | 1,Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all,1\n",
      "index=1 | 4,Forest fire near La Ronge Sask. Canada,1\n",
      "index=2 | 5,All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected,1\n",
      "index=3 | 6,13,000 people receive #wildfires evacuation orders in California ,1\n",
      "index=4 | 7,Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ,1\n",
      "shape of df_aug_class1: (3188, 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1\n",
       "5   8  #RockyFire Update => California Hwy. 20 closed...       1\n",
       "6  10  #flood #disaster Heavy rain causes flash flood...       1\n",
       "7  13  I'm on top of the hill and I can see a fire in...       1\n",
       "8  14  There's an emergency evacuation happening now ...       1\n",
       "9  15  I'm afraid that the tornado is coming to our a...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"./data/train_clean_v03.csv\")\n",
    "# train_ids = df_train['id']\n",
    "print(f\"shape of base data with spillovers fixed and duplicates removed: {df_train.shape}\")\n",
    "df_train_class0 = df_train.loc[df_train['target'] == 0, ['id', 'text', 'target']]\n",
    "df_train_class1 = df_train.loc[df_train['target'] == 1, ['id', 'text', 'target']]\n",
    "print(f\"shape of same base data with target == 0: {df_train_class0.shape}\")\n",
    "print(f\"shape of same base data with target == 1: {df_train_class1.shape}\")\n",
    "print()\n",
    "\n",
    "data = {'id': [], 'text': [], 'target': []}\n",
    "df_aug_class0 = pd.DataFrame(data, columns = ['id', 'text', 'target'])\n",
    "df_aug_class1 = pd.DataFrame(data, columns = ['id', 'text', 'target'])\n",
    "\n",
    "for i, row in df_train_class1.iterrows():\n",
    "    if i < 5:\n",
    "        print(f\"index={i} | {row['id']},{row['text']},{row['target']}\")\n",
    "    df_aug_class1.loc[len(df_aug_class1.index)] = [row['id'], row['text'], row['target']]\n",
    "\n",
    "print(f\"shape of df_aug_class1: {df_aug_class1.shape}\")\n",
    "print()\n",
    "df_aug_class1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11015bc3-0538-448e-9da5-54acd1a3507d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablaze for you Lord :D\n",
      "Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J\n"
     ]
    }
   ],
   "source": [
    "# df_train_class0.head(22)\n",
    "base_tweet_class0 = df_train_class0['text'].loc[df_train_class0['id'] == 57].values[0]\n",
    "base_tweet_class1 = df_train_class1['text'].loc[df_train_class1['id'] == 56].values[0]\n",
    "print(base_tweet_class0)\n",
    "print(base_tweet_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24dc782-8d97-4130-97ba-49f28cdbefdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write me a tweet similar to this one, under 141 characters, does not use contractions, but refers to a different activity and location: Ablaze for you Lord :D\n",
      "Write me a tweet similar to this one, under 141 characters, does not use contractions, but refers to a different disaster and location: Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J\n"
     ]
    }
   ],
   "source": [
    "# set up a single request\n",
    "context = \"You are a fiction writer who has observed a disaster and likes to tweet.\"\n",
    "start_prompt_class0 = \"Write me a tweet similar to this one, under 141 characters, \" + \\\n",
    "                      \"does not use contractions, but refers to a different activity and location: \"  # \"...activity...\n",
    "start_prompt_class1 = \"Write me a tweet similar to this one, under 141 characters, \" + \\\n",
    "                      \"does not use contractions, but refers to a different disaster and location: \"  # \"...disaster...\n",
    "complete_prompt_class0 = start_prompt_class0 + base_tweet_class0\n",
    "complete_prompt_class1 = start_prompt_class1 + base_tweet_class1\n",
    "print(complete_prompt_class0)\n",
    "print(complete_prompt_class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5f0c97-9745-45cc-a3c7-4158134c0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batch of 3 tweets\n",
    "# df_aug_class1_test3 = df_aug_class1.iloc[:3]\n",
    "# print(context)\n",
    "# df_aug_class1_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2654733b-259b-4a4a-9ba0-f885411bb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['id'].max()  # 10873, add 20,000 to id of augmented samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d139eb0-47c5-46d9-a882-28715944c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_chunk = df_train_class1.iloc[:100]\n",
    "# print(df_train_chunk.shape)\n",
    "# df_train_chunk.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a017492e-1377-402a-805f-847c5c087dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import projtools as pt\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "aug_offest = 20000\n",
    "aug_tweets_class0 = {}\n",
    "aug_tweets_class1 = {}\n",
    "df_train_chunk_class0 = df_train_class0.iloc[:100]\n",
    "df_train_chunk_class1 = df_train_class1.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0cd3a-2e07-4cf5-83a9-85bc7d54047b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# generate 100 class 0 tweets\n",
    "t0 = time.time()\n",
    "rows_processed = 1\n",
    "for i, row in df_train_chunk_class0.iterrows():\n",
    "    prompt_content = start_prompt_class0 + row['text']\n",
    "    gen_tweet = pt.get_aug_tweet(context, prompt_content)\n",
    "    aug_id = row['id'] + aug_offest\n",
    "    aug_tweets_class0[aug_id] = gen_tweet\n",
    "    if rows_processed % 10 == 0:\n",
    "        print(f\"processing row {rows_processed} with id {row['id']}\")\n",
    "    rows_processed += 1\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17fd58a4-0e08-4675-aad4-2558f8ff9886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to do 100 is 3.6672049085299174 minutes\n"
     ]
    }
   ],
   "source": [
    "gen_tweet_count = 100\n",
    "print(f\"time to do {gen_tweet_count} is {(t1-t0)/60.} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65f04f81-6091-4a9a-aa20-6a3df77bafb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.write_aug_tweets(aug_tweets_class0, 0, \"./data/aug_tweets_class0_v01prompt_0000_0100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a9f692-1900-42bc-a90e-50854d4075cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row 10 with id 15\n",
      "processing row 20 with id 66\n",
      "processing row 30 with id 98\n",
      "processing row 40 with id 126\n",
      "processing row 50 with id 139\n",
      "processing row 60 with id 208\n",
      "processing row 70 with id 222\n",
      "processing row 80 with id 244\n",
      "processing row 90 with id 262\n",
      "processing row 100 with id 289\n",
      "time to do 100 is 4.634544682502747 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate 100 class 1 tweets\n",
    "t0 = time.time()\n",
    "rows_processed = 1\n",
    "for i, row in df_train_chunk_class1.iterrows():\n",
    "    prompt_content = start_prompt_class1 + row['text']\n",
    "    gen_tweet = pt.get_aug_tweet(context, prompt_content)\n",
    "    aug_id = row['id'] + aug_offest\n",
    "    aug_tweets_class1[aug_id] = gen_tweet\n",
    "    if rows_processed % 10 == 0:\n",
    "        print(f\"processing row {rows_processed} with id {row['id']}\")\n",
    "    rows_processed += 1\n",
    "t1 = time.time()\n",
    "print(f\"time to do {gen_tweet_count} is {(t1-t0)/60.} minutes\")\n",
    "pt.write_aug_tweets(aug_tweets_class1, 1, \"./data/aug_tweets_class1_v01prompt_0000_0100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1056f6-2d5d-4aac-9c83-5cfaad5c581f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399fcdc9-732e-4fd3-90e1-280c94f777c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bb4a7-5fab-4175-96ad-729e0980face",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148e059-bb6f-4acb-9d5d-51777934ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = './data/first3_class1.pickle'\n",
    "# Store data (serialize) - commented out because it's already be done so just need to read\n",
    "with open(pickle_file, 'wb') as handle:\n",
    "    pickle.dump(aug_responses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data (deserialize)\n",
    "with open(pickle_file, 'rb') as handle:\n",
    "    aug_responses = pickle.load(handle)\n",
    "\n",
    "# print(aug_responses == unserialized_data)\n",
    "print(aug_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f90fe5-667e-463c-b5ac-082f0f522b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431e0ae-57ec-4905-a54a-6f342c9a76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(aug_responses.keys())\n",
    "for key in aug_responses.keys():\n",
    "    cgpt_response = aug_responses[key].choices[0].message.content\n",
    "    print(cgpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7803985-f346-4ba5-94d1-4ca15bbd346e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e197e-5a1d-4c19-b4d5-72dfbdf2aec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0b780-2ce0-4713-a154-ef0ec644c738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb8290-66a9-4b15-80a0-f43de9b4c55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ad330-d4e9-49a4-a993-5e0becbab06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
