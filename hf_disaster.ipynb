{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fc89f8-52f3-40d3-98d4-ce3938056e91",
   "metadata": {},
   "source": [
    "# Classification of Kaggle Disaster Data\n",
    "\n",
    "The goal of this notebook is to explore whether a HuggingFace model (HFM) can enhance the performance of non-transformer-based text classification models by augmenting the training data.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data used in this project comes from the kaggle *Natural Language Processing with Disaster Tweets* competition at:  \n",
    "\n",
    "https://www.kaggle.com/competitions/nlp-getting-started/data\n",
    "\n",
    "This data consists of two files: *train.csv* (x labled tweets) and *test.csv* (y unlabled tweets)\n",
    "\n",
    "Because the *test.csv* labels are not available, the *train.csv* file was split into the following two files:\n",
    "\n",
    "+ train_model.csv - data used to train model, x labeled tweets\n",
    "+ train_test.csv - not used to train model, used as *pseudo-test* data, y labeled tweets \n",
    "\n",
    "## Non-Transformer Models\n",
    "\n",
    "Two types of models are created and compared:\n",
    "\n",
    "1. Logistic Regression - This serves as the baseline\n",
    "2. Single-Hidden layer neural network with 100 nodes in the hidden layer\n",
    "\n",
    "## HuggingFace Models\n",
    "\n",
    "The *TBD* Hugging Face transformer model was used to provide both uninformed and informed assistance through augmenting the data used to train the non-transformer-based models.\n",
    "\n",
    "## Encodings\n",
    "\n",
    "Two types of encodings are used to vectorize the inputs:\n",
    "\n",
    "1. One-hot encoding\n",
    "2. Twitter GloVe embedding: https://nlp.stanford.edu/data/glove.twitter.27B.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e8d7b-78a3-4581-9ae2-688cdf694678",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Manual inspection of train.csv\n",
    "\n",
    "The following issues observered in the data are listed below.  They are numbered to indicate the order in which they were processed.  For example, spillover lines were fixed first, then URLs, etc.  This order is important because removing things like punctuation too early would make things like identifying user names or hashtags in a tweet impossible or make URLs invalid.\n",
    "\n",
    "### 1. Spillover lines\n",
    "\n",
    "The first issue we see with this data is that while most of the samples are on there own line. Here are few examples:\n",
    "\n",
    ">`61,ablaze,,\"on the outside you're ablaze and alive`  \n",
    ">`but you're dead inside\",0`  \n",
    ">`74,ablaze,India,\"Man wife get six years jail for setting ablaze niece`  \n",
    ">`http://t.co/eV1ahOUCZA\",1`  \n",
    ">`86,ablaze,Inang Pamantasan,\"Progressive greetings!`  \n",
    ">  \n",
    ">`In about a month students would have set their pens ablaze in The Torch Publications'... http://t.co/9FxPiXQuJt\",0`  \n",
    ">`117,accident,,\"mom: 'we didn't get home as fast as we wished'`  \n",
    ">`me: 'why is that?'`  \n",
    ">`mom: 'there was an accident and some truck spilt mayonnaise all over ??????\",0`\n",
    "\n",
    "The custom function `fix_spillover_lines` was written to fix these lines. Its code is available in the projtools module.\n",
    "\n",
    "### 2. Normalizing URLs\n",
    "\n",
    "Some tweet contain one or more URLs.  I assume that the content of a ULR does not contain any useful.  However, the count of URLs occuring in a tweet may be a useful feature and are counted before removing them.  About 90% of the URLs in the training data are of the form `http://t.co/<10 digit hash>`. For example: `http://t.co/9FxPiXQuJt`.  In about 10% of cases, these URLs start with `https:\\\\`.\n",
    "\n",
    "#### 2.1 Counting URLs in each tweet\n",
    "\n",
    "The custom function `make_url_counts` is used to create a `url_count` feature/column.  This is called before removing the URLs as described in the next section.\n",
    "\n",
    "#### 2.2 Removing URLs\n",
    "\n",
    "The `replace_urls` function replaces each URL by the string \"web link\".\n",
    "\n",
    "### 3. Expanding contractions\n",
    "\n",
    "The last step before building a text classification model is the encoding of words into vectors.  Before we do this encoding, each text entry needs to consist of single words.  Contractions are especially common in the text of tweets as they allow the communicator to relay the same amount of information with less characters.  But because contractions like \"I'm\", \"you're\", etc. represent combinations of words like \"I am\" and \"you are\" respectively, they need to be expanded into their corresponding single-word forms before they are encoded.\n",
    "\n",
    "This expansion needs to happen before removing punctutation since contractions are typically created with an apostrophy (`'`).  The `contractions` library was chosen to expand contractions.\n",
    "\n",
    "### 4. Removing punctuation and digits\n",
    "\n",
    "Removing punctuation and digits needs to be done just on the text of the tweets which are in the `text` column.  Each column will be extracted by reading the `csv` file into a dataframe so the `text` column can be worked on in isolation.\n",
    "\n",
    "#### 4.1 Process Twitter-specifc characters\n",
    "\n",
    "Because the `@` and `#` characters have special meaning in tweets, they need to be processed before removing other punctuation.  When a `@<username>` is seen in a tweet, it is a reference to a user names `username`.  When a `#<hashname>` is seen in a tweet, it specifies a hashtag which is a reference to all tweet tweets that use the `hashname` hashtag.  In processing these characters, `@<username>` is converted to `at username` and `#<hashname>` is converted to `hashtag hashname`.\n",
    "\n",
    "#### 4.2 Remove remaining punctuation\n",
    "\n",
    "The custom function `replace_with_space` is run to remove any remaining punctuation.\n",
    "\n",
    "#### 4.3 Remove digits\n",
    "\n",
    "The function `replace_with_space` is run to remove any remaining digits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e97b95-4b7e-4499-933a-5b3f5653c938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8562 3700\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string as st\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To get around the \"UnicodeDecodeError: 'charmap' codec can't decode byte ...\" error,\n",
    "# need specify encoding when reading this data in as described in the solution I upvoted here:\n",
    "# https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character\n",
    "# with open(\"./data/train.csv\", encoding=\"utf8\") as f:  # works, but setting errors removes unneeded chars\n",
    "with open(\"./data/train.csv\", encoding=\"utf8\", errors='ignore') as f_train:\n",
    "    content_train = f_train.readlines()\n",
    "\n",
    "with open(\"./data/test.csv\", encoding=\"utf8\", errors='ignore') as f_test:\n",
    "    content_test = f_test.readlines()\n",
    "\n",
    "print(len(content_train), len(content_test))  # 8562, 3700  BEFORE applying any fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7721fda8-fdfb-4584-b588-94398e0c45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,keyword,location,text,target\n",
      "61,ablaze,,\"on the outside you're ablaze and alive\n",
      "but you're dead inside\",0\n",
      "74,ablaze,India,\"Man wife get six years jail for setting ablaze niece\n",
      "http://t.co/eV1ahOUCZA\",1\n",
      "86,ablaze,Inang Pamantasan,\"Progressive greetings!\n",
      "\n",
      "In about a month students would have set their pens ablaze in The Torch Publications'... http://t.co/9FxPiXQuJt\",0\n"
     ]
    }
   ],
   "source": [
    "# print some examples of spillover lines\n",
    "with open(\"./debug/train_debug_chunk.txt\", encoding=\"utf8\", errors='ignore') as f:\n",
    "    content_train_debug = f.readlines()\n",
    "\n",
    "for i in [0, 42, 43, 53, 54, 64, 65, 66]:\n",
    "    print(content_train_debug[i].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1f8deb-d216-4a62-bf8a-cd85e68e5295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,keyword,location,text,target\n",
      "32,,,London is cool ;),0\n",
      "53,ablaze,\"London, UK\",On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N,0\n",
      "61,ablaze,,\"on the outside you're ablaze and alive but you're dead inside\",0\n",
      "74,ablaze,India,\"Man wife get six years jail for setting ablaze niece http://t.co/eV1ahOUCZA\",1\n",
      "86,ablaze,Inang Pamantasan,\"Progressive greetings!  In about a month students would have set their pens ablaze in The Torch Publications'... http://t.co/9FxPiXQuJt\",0\n",
      "117,accident,,\"mom: 'we didn't get home as fast as we wished' me: 'why is that?' mom: 'there was an accident and some truck spilt mayonnaise all over ??????\",0\n",
      "119,accident,,Can wait to see how pissed Donnie is when I tell him I was in ANOTHER accident??,0\n",
      "120,accident,\"Arlington, TX\",#TruckCrash Overturns On #FortWorth Interstate http://t.co/Rs22LJ4qFp Click here if you've been in a crash&gt;http://t.co/Ld0unIYw4k,1\n"
     ]
    }
   ],
   "source": [
    "import projtools as pt\n",
    "# test the fix for the spillover lines on the training data\n",
    "fixed_train_debug = pt.fix_spillover_lines(content_train_debug)\n",
    "\n",
    "# for i, line in enumerate(fixed_list):\n",
    "#     print(i, line)\n",
    "\n",
    "# check that good lines are still good and spillover lines (*) are fixed\n",
    "#id = header 32  25 *61 *74 *86 *117 119 120\n",
    "for j in [0, 22, 36, 42, 52, 62, 81, 83, 84]:\n",
    "    print(fixed_train_debug[j])  # spillover lines are now consolidated to a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e3650a-b636-45c3-ab2d-719d5b0a64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the spillover lines in the train and test data, then write out fixed data\n",
    "fixed_train = pt.fix_spillover_lines(content_train)\n",
    "with open(file='./data/train_clean_v01.csv', mode='w', encoding=\"utf8\", errors='ignore') as f_train_out:\n",
    "    for line in fixed_train:\n",
    "        f_train_out.write(line)\n",
    "        f_train_out.write('\\n')\n",
    "\n",
    "fixed_test = pt.fix_spillover_lines(content_test)\n",
    "with open(file='./data/test_clean_v01.csv', mode='w', encoding=\"utf8\", errors='ignore') as f_test_out:\n",
    "    for line in fixed_test:\n",
    "        f_test_out.write(line)\n",
    "        f_test_out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092512ed-b1d6-45c3-aca8-bb4a5643d9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48,ablaze,Birmingham,@bbcmtd Wholesale Markets ablaze web link,1,1\n",
      "49,ablaze,Est. September 2012 - Bristol,We always try to bring the heavy. #metal #RT web link,0,1\n",
      "50,ablaze,AFRICA,#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. web link,1,1\n",
      "52,ablaze,\"Philadelphia, PA\",Crying out for more! Set me ablaze,0,0\n",
      "53,ablaze,\"London, UK\",On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE web link,0,1\n",
      "54,ablaze,Pretoria,@PhDSquares #mufc they've built so much hype around new acquisitions but I doubt they will set the EPL ablaze this season.,0,0\n",
      "55,ablaze,World Wide!!,INEC Office in Abia Set Ablaze - web link,1,1\n",
      "56,ablaze,,Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  web link,1,1\n",
      "57,ablaze,Paranaque City,Ablaze for you Lord :D,0,0\n",
      "59,ablaze,Live On Webcam,Check these out: web link web link web link web link #nsfw,0,4\n",
      "61,ablaze,,\"on the outside you're ablaze and alive but you're dead inside\",0,0\n",
      "62,ablaze,milky way,Had an awesome time visiting the CFC head office the ancop site and ablaze. Thanks to Tita Vida for taking care of us ??,0,0\n",
      "63,ablaze,,SOOOO PUMPED FOR ABLAZE ???? @southridgelife,0,0\n",
      "64,ablaze,,I wanted to set Chicago ablaze with my preaching... But not my hotel! web link,0,1\n",
      "65,ablaze,,I gained 3 followers in the last week. You? Know your stats and grow with web link,0,1\n",
      "66,ablaze,\"GREENSBORO,NORTH CAROLINA\",How the West was burned: Thousands of wildfires ablaze in California alone web link,1,1\n",
      "67,ablaze,,Building the perfect tracklist to life leave the streets ablaze,0,0\n",
      "68,ablaze,Live On Webcam,Check these out: web link web link web link web link #nsfw,0,4\n",
      "71,ablaze,England.,First night with retainers in. It's quite weird. Better get used to it; I have to wear them every single night for the next year at least.,0,0\n",
      "73,ablaze,\"Sheffield Township, Ohio\",Deputies: Man shot before Brighton home set ablaze web link,1,1\n",
      "74,ablaze,India,\"Man wife get six years jail for setting ablaze niece web link\",1,1\n",
      "76,ablaze,Barbados,SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintendent Lanford Salmon has r ... - web link web link,0,2\n",
      "77,ablaze,Anaheim,Police: Arsonist Deliberately Set Black Church In North CarolinaåÊAblaze web link,1,1\n",
      "78,ablaze,Abuja,Noches El-Bestia '@Alexis_Sanchez: happy to see my teammates and training hard ?? goodnight gunners.?????? web link',0,1\n",
      "79,ablaze,USA,#Kurds trampling on Turkmen flag later set it ablaze while others vandalized offices of Turkmen Front in #Diyala web link,1,1\n",
      "80,ablaze,South Africa,TRUCK ABLAZE : R21. VOORTREKKER AVE. OUTSIDE OR TAMBO INTL. CARGO SECTION. web link,1,1\n",
      "81,ablaze,\"Sao Paulo, Brazil\",Set our hearts ablaze and every city was a gift And every skyline was like a kiss upon the lips @Û_ web link,0,1\n",
      "82,ablaze,hollywoodland ,They sky was ablaze tonight in Los Angeles. I'm expecting IG and FB to be filled with sunset shots if I know my peeps!!,0,0\n",
      "83,ablaze,\"Edmonton, Alberta - Treaty 6\",How the West was burned: Thousands of wildfires ablaze in #California alone web link #climate #energy web link,1,2\n",
      "85,ablaze,,Revel in yours wmv videos by means of mac farewell ablaze wmv en route to dvd: GtxRWm,0,0\n",
      "86,ablaze,Inang Pamantasan,\"Progressive greetings!  In about a month students would have set their pens ablaze in The Torch Publications'... web link\",0,1\n",
      "89,ablaze,Twitter Lockout in progress,Rene Ablaze &amp; Jacinta - Secret 2k13 (Fallen Skies Edit) - Mar 30 2013  web link,0,1\n",
      "91,ablaze,\"Concord, CA\",@Navista7 Steve these fires out here are something else! California is a tinderbox - and this clown was setting my 'hood ablaze @News24680,1,0\n",
      "92,ablaze,\"Calgary, AB\",#NowPlaying: Rene Ablaze &amp; Ian Buff - Magnitude web link  #EDM,0,1\n",
      "93,ablaze,Birmingham,@nxwestmidlands huge fire at Wholesale markets ablaze web link,1,1\n",
      "95,ablaze,San Francisco,@ablaze what time does your talk go until? I don't know if I can make it due to work.,0,0\n",
      "96,accident,CLVLND,'I can't have kids cuz I got in a bicycle accident &amp; split my testicles. it's impossible for me to have kids' MICHAEL YOU ARE THE FATHER,0,0\n",
      "97,accident,\"Nashville, TN\",Accident on I-24 W #NashvilleTraffic. Traffic moving 8m slower than usual. web link,1,1\n",
      "98,accident,\"Santa Clara, CA\",Accident center lane blocked in #SantaClara on US-101 NB before Great America Pkwy #BayArea #Traffic web link,1,1\n",
      "100,accident,UK,web link Had a #personalinjury accident this summer? Read our advice &amp; see how a #solicitor can help #OtleyHour,0,1\n",
      "102,accident,\"St. Louis, MO\",#stlouis #caraccidentlawyer Speeding Among Top Causes of Teen Accidents web link web link Car Accident teeÛ_,0,2\n",
      "104,accident,\"Walker County, Alabama\",Reported motor vehicle accident in Curry on Herman Rd near Stephenson involving an overturned vehicle. Please use... web link,1,1\n",
      "105,accident,Australia,BigRigRadio Live Accident Awareness,1,0\n",
      "107,accident,North Carolina,I-77 Mile Marker 31 South Mooresville  Iredell Vehicle Accident Ramp Closed at 8/6 1:18 PM,1,0\n",
      "109,accident,,RT @SleepJunkies: Sleeping pills double your risk of a car accident web link,0,1\n",
      "110,accident,Norf Carolina,'By accident' they knew what was gon happen web link,0,1\n",
      "112,accident,\"San Mateo County, CA\",Traffic accident N CABRILLO HWY/MAGELLAN AV MIR (08/06/15 11:03:58),1,0\n",
      "113,accident,North Carolina,I-77 Mile Marker 31 to 40 South Mooresville  Iredell Vehicle Accident Congestion at 8/6 1:18 PM,1,0\n",
      "114,accident,\"Njoro, Kenya\",the pastor was not in the scene of the accident......who was the owner of the range rover ?,1,0\n",
      "117,accident,,\"mom: 'we didn't get home as fast as we wished' me: 'why is that?' mom: 'there was an accident and some truck spilt mayonnaise all over ??????\",0,0\n",
      "118,accident,Your Sister's Bedroom,I was in a horrible car accident this past Sunday. I'm finally able to get around. Thank you GOD??,1,0\n",
      "119,accident,,Can wait to see how pissed Donnie is when I tell him I was in ANOTHER accident??,0,0\n",
      "120,accident,\"Arlington, TX\",#TruckCrash Overturns On #FortWorth Interstate web link Click here if you've been in a crash&gt;web link,1,2\n",
      "121,accident,\"South Bloomfield, OH\",Accident in #Ashville on US 23 SB before SR 752 #traffic web link,1,1\n",
      "126,accident,,Carolina accident: Motorcyclist Dies in I-540 Crash With Car That Crossed Median: A motorcycle rider traveling... web link,1,1\n",
      "128,accident,\"New Hanover County, NC\",FYI CAD:FYI: ;ACCIDENT PROPERTY DAMAGE;NHS;999 PINER RD/HORNDALE DR,1,0\n",
      "129,accident,Maldives,RT nAAYf: First accident in years. Turning onto Chandanee Magu from near MMA. Taxi rammed into me while I was halfway turned. Everyone confÛ_,1,0\n",
      "130,accident,\"Manchester, NH\",Accident left lane blocked in #Manchester on Rt 293 NB before Eddy Rd stop and go traffic back to NH-3A delay of 4 mins #traffic,1,0\n",
      "131,accident,\"Wilmington, NC\",;ACCIDENT PROPERTY DAMAGE; PINER RD/HORNDALE DR,1,0\n",
      "132,accident,,???? it was an accident web link,0,1\n",
      "133,accident,\"New Hanover County, NC\",FYI CAD:FYI: ;ACCIDENT PROPERTY DAMAGE;WPD;1600 S 17TH ST,1,0\n",
      "134,accident,,8/6/2015@2:09 PM: TRAFFIC ACCIDENT NO INJURY at 2781 WILLIS FOREMAN RD web link,1,1\n",
      "135,accident,global,Aashiqui Actress Anu Aggarwal On Her Near-Fatal Accident web link,1,1\n",
      "136,accident,Alberta | Sask. | Montana,Suffield Alberta Accident web link,1,1\n",
      "137,accident,Charlotte,9 Mile backup on I-77 South...accident blocking the Right 2 Lanes at Exit 31 Langtree Rd...consider NC 115 or NC 150 to NC 16 as alternate,1,0\n",
      "138,accident,\"Baton Rouge, LA\",Has an accident changed your life? We will help you determine options that can financially support life care plans and on-going treatment.,0,0\n",
      "139,accident,\"Hagerstown, MD\",#BREAKING: there was a deadly motorcycle car accident that happened to #Hagerstown today. I'll have more details at 5 @Your4State. #WHAG,1,0\n",
      "141,accident,\"Gloucestershire , UK\",@flowri were you marinading it or was it an accident?,0,0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# count urls and add url_count column\n",
    "train_url_counts = pt.make_url_counts(fixed_train)\n",
    "test_url_counts = pt.make_url_counts(fixed_test)\n",
    "\n",
    "# test ulr fixer function\n",
    "revised_train_lines = pt.replace_urls(train_url_counts)\n",
    "revised_test_lines = pt.replace_urls(test_url_counts)\n",
    "# just look at training data\n",
    "for revised_line in revised_train_lines[32:100]:\n",
    "    print(revised_line)\n",
    "\n",
    "# write updated files\n",
    "pt.write_lines_to_csv(list_of_lines = revised_train_lines, file_name = \"./data/train_clean_v02.csv\")\n",
    "pt.write_lines_to_csv(list_of_lines = revised_test_lines, file_name = \"./data/test_clean_v02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ba51f3-d53e-4eb8-b01c-9208f230ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand contractions\n",
    "expand_train_contractions = pt.expand_contractions(revised_train_lines)\n",
    "expand_test_contractions = pt.expand_contractions(revised_test_lines)\n",
    "# write updated files\n",
    "pt.write_lines_to_csv(list_of_lines = expand_train_contractions, file_name = \"./data/train_clean_v03.csv\")\n",
    "pt.write_lines_to_csv(list_of_lines = expand_test_contractions, file_name = \"./data/test_clean_v03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e4205-1ab6-4d45-b087-f89680e52a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37f1e7-3f59-48ef-abde-5c943dd9bcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3519d-c831-4f63-a0e7-a1c8db32cc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a857ecd-d87d-45d0-8905-50bd473e8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace special twitter characters @ and # with markers (\"at\", \"hash tag\")\n",
    "fix_train_special_chars = pt.replace_twitter_specials(revised_train_lines)\n",
    "\n",
    "# check that lines with @ and # are fixed\n",
    "#id = header 48   49 54  91  139\n",
    "for j in [0, 32, 33, 37, 64, 98]:\n",
    "    print(fix_train_special_chars[j])  # looks good\n",
    "\n",
    "fix_test_special_chars = pt.replace_twitter_specials(revised_test_lines)\n",
    "pt.write_lines_to_csv(list_of_lines = fix_train_special_chars, file_name = \"./data/train_clean_v03.csv\", index=False, encoding=\"utf8\")\n",
    "pt.write_lines_to_csv(list_of_lines = fix_test_special_chars, file_name = \"./data/test_clean_v03.csv\", index=False, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f525a6-3f50-4de1-8e2e-540cb06ffca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# break out the text column so it can be operated on separately\n",
    "df_train04 = pd.read_csv('./data/train_clean_v03.csv', encoding=\"utf8\")\n",
    "df_test04 = pd.read_csv('./data/test_clean_v03.csv', encoding=\"utf8\")\n",
    "\n",
    "text_train = df_train04['text'].to_list()\n",
    "text_test = df_test04['text'].to_list()\n",
    "\n",
    "text_train04 = pt.remove_digits_and_punc(text_train)\n",
    "text_test04 = pt.remove_digits_and_punc(text_test)\n",
    "\n",
    "# replace text column with updated versions\n",
    "df_train04['text'] = text_train04\n",
    "df_test04['text'] = text_test04\n",
    "\n",
    "# write out updated data sets\n",
    "df_train04.to_csv('./data/train_clean_v04.csv', index=False, encoding=\"utf8\")\n",
    "df_test04.to_csv('./data/test_clean_v04.csv', index=False, encoding=\"utf8\")\n",
    "\n",
    "print(len(text_train), len(text_test), df_train04.shape, df_test04.shape)  # 7613 3263 (7613, 6) (3263, 5)\n",
    "df_train04.loc[20:40, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229bc8d-a043-497c-a637-455a4dbba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train04[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4fa20-b2a4-44c9-9b01-f3208dac8612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa35c0-d90b-4404-8815-90b6d0ef7a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717c837-1f29-41ee-af2b-a4f2c115c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training data as dataframe\n",
    "# import pandas as pd\n",
    "\n",
    "# df_train = pd.read_csv('./data/train_clean_v01.csv', encoding=\"utf8\")\n",
    "# print(df_train.shape)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b743c4f-f6ed-4b70-b83c-1881c7b0e70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffa728-3fe8-4864-a2cd-3be111517140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370df4c-c12b-408f-a0e4-e80bf02ba53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf09c8-2132-48bf-92e4-f67178763e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7616c-9488-4a06-a782-4103d3d9fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60f35d-b628-4dbe-bd45-f0432d23dce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce33e5b-ffa0-4a32-908a-caf7f9e02be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305007e-7795-486c-bf8a-6ca6968dc9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
